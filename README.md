# EDCNN:Identification of Genome-Wide RNA-binding Proteins Using Evolutionary Deep Convolutional Neural Network
<br>
The tool is developed for identification of genome-wide RNA-binding proteins using evolutionary deep convolutional neural network.<br>
In this package, we provides resources including: source codes of the EDCNN model, usage examples. 

The flowcharts of EDCNN is following:<br>

## Requirements:
EDCNN is written in Python3 and requires the following dependencies to be installed: <br>
+ [PyTorch](http://pytorch.org/) <br>
+ [Sklearn](https://github.com/scikit-learn/scikit-learn)
+ [deap](https://github.com/deap/deap)
+ [numpy](http://numpy.org/)
+ [weblogo](http://weblogo.berkeley.edu/)

## Installation
We recommend you to build a python virtual environment with [Anaconda](https://docs.anaconda.com/anaconda/install/linux/). 
```
conda create -n edcnn python=3.6
conda activate edcnn
git clone https://github.com/yaweiwang1232/EDCNN.git
cd EDCNN
python3 -m pip install -r requirements.txt
```






## Data 
For RBP-24, the training and testing data can be downloaded from http://www.bioinf.uni-freiburg.de/Software/GraphProt/GraphProt_CLIP_sequences.tar.bz2 and decompress it in current dir. It has 24 experiments of 21 RBPs.<br>
For RBP-47, the trainig and testing data can be downloaded https://github.com/yaweiwang1232/EDCNN/tree/main/RBP47_Dataset.

## Usage:

```
python edcnn.py [-h] [--posi <postive_sequecne_file>]
                 [--nega <negative_sequecne_file>]
                 [--model_type MODEL_TYPE] 
                 [--out_file OUT_FILE]
                 [--motif MOTIF] [--train TRAIN] 
                 [--model_file MODEL_FILE] 
                 [--predict PREDICT]
                 [--motif_dir MOTIF_DIR]
                 [--batch_size BATCH_SIZE] 
                 [--num_filters NUM_FILTERS] 
                 [--n_epochs N_EPOCHS] 
                 [--population_size POPULATION_SIZE]
                 [--generation_number GENERATION_NUMBER]
```


Function | Description
---|---
run_edcnn(args) | implementation process of EDCNN
train_network | Optimizing neural network parameters using different optimizers in train step
generate_offspring | Adding Gaussian noise to neural network model parameters to generate offspring
individual_evaluation | evaluate individuals in population and output fitness
predict_network | predict using the best model



                 
## Use case:
Take ALKBH5 as an example, if you want to predict the binding sites for RBP ALKBH5 using local and global CNNs <br>
### 1.train step:


```
python3 edcnn.py --posi=GraphProt_CLIP_sequences/ALKBH5_Baltz2012.train.positives.fa 
                 --nega=GraphProt_CLIP_sequences/ALKBH5_Baltz2012.train.negatives.fa 
                 --model_type=CNN 
                 --model_file=model.pkl 
                 --train=True 
                 --population_size=population_size
                 --generation_number=generation_number
```
<br>
Our propose EDCNN will save 'best.model.pkl.local' and 'best.model.pkl.global' for local and global CNNs. <br>

### 2.predict step:

```
python3 edcnn.py --posi=GraphProt_CLIP_sequences/ALKBH5_Baltz2012.ls.positives.fa 
                 --nega=GraphProt_CLIP_sequences/ALKBH5_Baltz2012.ls.negatives.fa 
                 --model_type=CNN 
                 --model_file=model.pkl 
                 --predict=True 
```
<br>
Predict step, we can also utilize the 'best.model.pkl.local' and 'best.model.pkl.global' in model dir generated by edcnn to calculate the mean AUCs (0.944) of 24 experiments.<br>

### 3.detect motif step:

```
python3 edcnn.py --posi=GraphProt_CLIP_sequences/ALKBH5_Baltz2012.train.positives.fa 
                 --nega=GraphProt_CLIP_sequences/ALKBH5_Baltz2012.train.negatives.fa
                 --model_type=CNN 
                 --model_file=model.pkl 
                 --motif=True 
                 --motif_dir=motifs
```
<br>
You need install WebLogo(http://weblogo.berkeley.edu/) and TOMTOM in MEME Suite(http://meme-suite.org/) to search identifyed motifs against known motifs of RBPs. <br> 
<br>

## Contact
For questions, comments and concerns, please contact
Yawei Wang(wangyw19@mails.jlu.edu.cn), Yuning Yang, and Xiangtao Li.
